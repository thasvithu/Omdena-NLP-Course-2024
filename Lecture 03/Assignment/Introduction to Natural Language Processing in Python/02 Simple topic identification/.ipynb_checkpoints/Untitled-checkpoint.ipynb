{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6843a0a2",
   "metadata": {},
   "source": [
    "# Word counts with bag-of-words\n",
    "- Bag of Words (BoW) is a imple and powerful technique for converting text into numerical features that can be used in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5702cd",
   "metadata": {},
   "source": [
    "![q1.png](q1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f6c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The cat is in the box. The cat box.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0059e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0243ebe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'cat', 'is', 'in', 'the', 'box', '.', 'the', 'cat', 'box', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text.lower())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8fb7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'box', 'cat', 'in', 'is', 'the']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Vocabulary\n",
    "vocab = sorted(set(tokens))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71481d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99e6c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 3, 'cat': 2, 'box': 2, '.': 2, 'is': 1, 'in': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting Frequencies\n",
    "word_freq = Counter(tokens)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91a532",
   "metadata": {},
   "source": [
    "#### Building a Counter with bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52c598",
   "metadata": {},
   "source": [
    "![q2.png](q2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe77b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem-solving\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d825a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acdedf69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'is',\n",
       " 'intelligence',\n",
       " 'demonstrated',\n",
       " 'by',\n",
       " 'machines',\n",
       " ',',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'displayed',\n",
       " 'by',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'Leading',\n",
       " 'AI',\n",
       " 'textbooks',\n",
       " 'define',\n",
       " 'the',\n",
       " 'field',\n",
       " 'as',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " '``',\n",
       " 'intelligent',\n",
       " 'agents',\n",
       " \"''\",\n",
       " ':',\n",
       " 'any',\n",
       " 'device',\n",
       " 'that',\n",
       " 'perceives',\n",
       " 'its',\n",
       " 'environment',\n",
       " 'and',\n",
       " 'takes',\n",
       " 'actions',\n",
       " 'that',\n",
       " 'maximize',\n",
       " 'its',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'successfully',\n",
       " 'achieving',\n",
       " 'its',\n",
       " 'goals',\n",
       " '.',\n",
       " 'Colloquially',\n",
       " ',',\n",
       " 'the',\n",
       " 'term',\n",
       " '``',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " \"''\",\n",
       " 'is',\n",
       " 'often',\n",
       " 'used',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'machines',\n",
       " '(',\n",
       " 'or',\n",
       " 'computers',\n",
       " ')',\n",
       " 'that',\n",
       " 'mimic',\n",
       " '``',\n",
       " 'cognitive',\n",
       " \"''\",\n",
       " 'functions',\n",
       " 'that',\n",
       " 'humans',\n",
       " 'associate',\n",
       " 'with',\n",
       " 'the',\n",
       " 'human',\n",
       " 'mind',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " '``',\n",
       " 'learning',\n",
       " \"''\",\n",
       " 'and',\n",
       " '``',\n",
       " 'problem-solving',\n",
       " \"''\",\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the article: tokens\n",
    "tokens = word_tokenize(article)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3e8bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'ai',\n",
       " ')',\n",
       " 'is',\n",
       " 'intelligence',\n",
       " 'demonstrated',\n",
       " 'by',\n",
       " 'machines',\n",
       " ',',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'displayed',\n",
       " 'by',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'leading',\n",
       " 'ai',\n",
       " 'textbooks',\n",
       " 'define',\n",
       " 'the',\n",
       " 'field',\n",
       " 'as',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " '``',\n",
       " 'intelligent',\n",
       " 'agents',\n",
       " \"''\",\n",
       " ':',\n",
       " 'any',\n",
       " 'device',\n",
       " 'that',\n",
       " 'perceives',\n",
       " 'its',\n",
       " 'environment',\n",
       " 'and',\n",
       " 'takes',\n",
       " 'actions',\n",
       " 'that',\n",
       " 'maximize',\n",
       " 'its',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'successfully',\n",
       " 'achieving',\n",
       " 'its',\n",
       " 'goals',\n",
       " '.',\n",
       " 'colloquially',\n",
       " ',',\n",
       " 'the',\n",
       " 'term',\n",
       " '``',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " \"''\",\n",
       " 'is',\n",
       " 'often',\n",
       " 'used',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'machines',\n",
       " '(',\n",
       " 'or',\n",
       " 'computers',\n",
       " ')',\n",
       " 'that',\n",
       " 'mimic',\n",
       " '``',\n",
       " 'cognitive',\n",
       " \"''\",\n",
       " 'functions',\n",
       " 'that',\n",
       " 'humans',\n",
       " 'associate',\n",
       " 'with',\n",
       " 'the',\n",
       " 'human',\n",
       " 'mind',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " '``',\n",
       " 'learning',\n",
       " \"''\",\n",
       " 'and',\n",
       " '``',\n",
       " 'problem-solving',\n",
       " \"''\",\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the tokens into lowercase: lower_tokens\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "lower_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add34677",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 5,\n",
       "         '``': 5,\n",
       "         \"''\": 5,\n",
       "         'intelligence': 4,\n",
       "         'that': 4,\n",
       "         ',': 3,\n",
       "         'and': 3,\n",
       "         '.': 3,\n",
       "         'its': 3,\n",
       "         'artificial': 2,\n",
       "         '(': 2,\n",
       "         'ai': 2,\n",
       "         ')': 2,\n",
       "         'is': 2,\n",
       "         'by': 2,\n",
       "         'machines': 2,\n",
       "         'to': 2,\n",
       "         'humans': 2,\n",
       "         'as': 2,\n",
       "         'of': 2,\n",
       "         'demonstrated': 1,\n",
       "         'in': 1,\n",
       "         'contrast': 1,\n",
       "         'natural': 1,\n",
       "         'displayed': 1,\n",
       "         'animals': 1,\n",
       "         'leading': 1,\n",
       "         'textbooks': 1,\n",
       "         'define': 1,\n",
       "         'field': 1,\n",
       "         'study': 1,\n",
       "         'intelligent': 1,\n",
       "         'agents': 1,\n",
       "         ':': 1,\n",
       "         'any': 1,\n",
       "         'device': 1,\n",
       "         'perceives': 1,\n",
       "         'environment': 1,\n",
       "         'takes': 1,\n",
       "         'actions': 1,\n",
       "         'maximize': 1,\n",
       "         'chance': 1,\n",
       "         'successfully': 1,\n",
       "         'achieving': 1,\n",
       "         'goals': 1,\n",
       "         'colloquially': 1,\n",
       "         'term': 1,\n",
       "         'often': 1,\n",
       "         'used': 1,\n",
       "         'describe': 1,\n",
       "         'or': 1,\n",
       "         'computers': 1,\n",
       "         'mimic': 1,\n",
       "         'cognitive': 1,\n",
       "         'functions': 1,\n",
       "         'associate': 1,\n",
       "         'with': 1,\n",
       "         'human': 1,\n",
       "         'mind': 1,\n",
       "         'such': 1,\n",
       "         'learning': 1,\n",
       "         'problem-solving': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Counter with the lowercase tokens: bow_simple\n",
    "bow_simple = Counter(lower_tokens)\n",
    "bow_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d04525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 5), ('``', 5), (\"''\", 5), ('intelligence', 4), ('that', 4), (',', 3), ('and', 3), ('.', 3), ('its', 3), ('artificial', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Print the 10 most common tokens\n",
    "print(bow_simple.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f64f2",
   "metadata": {},
   "source": [
    "# Simple text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a6dbc",
   "metadata": {},
   "source": [
    "![q3.png](q4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5b08c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff0b8bd9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'text',\n",
       " 'for',\n",
       " 'testing',\n",
       " 'bag',\n",
       " 'of',\n",
       " 'words',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'box',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = \"This is an example text for testing bag of words. The cat is in the box. The cat box.\"\n",
    "tokens = word_tokenize(article)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2125c546",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'text',\n",
       " 'for',\n",
       " 'testing',\n",
       " 'bag',\n",
       " 'of',\n",
       " 'words',\n",
       " '.',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " '.',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'box',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the tokens into lowercase\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "lower_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d6ffd5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'text',\n",
       " 'for',\n",
       " 'testing',\n",
       " 'bag',\n",
       " 'of',\n",
       " 'words',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'box']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out non-alphabetic tokens\n",
    "alpha_only = [t for t in lower_tokens if t.isalpha()]\n",
    "alpha_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aecc7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'text', 'testing', 'bag', 'words', 'cat', 'box', 'cat', 'box']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "english_stops = set(stopwords.words('english'))\n",
    "no_stops = [t for t in alpha_only if t not in english_stops]\n",
    "no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a7ca17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36696589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'text', 'testing', 'bag', 'word', 'cat', 'box', 'cat', 'box']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize the tokens\n",
    "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a3a3e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'cat': 2,\n",
       "         'box': 2,\n",
       "         'example': 1,\n",
       "         'text': 1,\n",
       "         'testing': 1,\n",
       "         'bag': 1,\n",
       "         'word': 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the bag-of-words\n",
    "bow = Counter(lemmatized)\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b166e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('box', 2), ('example', 1), ('text', 1), ('testing', 1), ('bag', 1), ('word', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Print the 10 most common tokens\n",
    "print(bow.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80908383",
   "metadata": {},
   "source": [
    "# Introduction to gensim\n",
    "- Gensim is an open-source library designed for natural language processing (NLP), particularly focused on unsupervised topic modeling and natural language understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3af7e",
   "metadata": {},
   "source": [
    "![q5.png](q5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "408a12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0af549d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    [\"computer\", \"science\", \"study\", \"of\", \"computers\", \"and\", \"computational\", \"systems\"],\n",
    "    [\"artificial\", \"intelligence\", \"branch\", \"of\", \"computer\", \"science\", \"concerned\", \"with\", \"making\", \"computers\", \"behave\", \"like\", \"humans\"],\n",
    "    [\"machine\", \"learning\", \"subset\", \"of\", \"artificial\", \"intelligence\", \"focused\", \"on\", \"algorithms\", \"that\", \"allow\", \"computers\", \"to\", \"learn\", \"from\", \"data\"],\n",
    "    [\"neural\", \"networks\", \"computing\", \"systems\", \"inspired\", \"by\", \"the\", \"biological\", \"neural\", \"networks\", \"that\", \"constitute\", \"animal\", \"brains\"],\n",
    "    [\"data\", \"science\", \"interdisciplinary\", \"field\", \"that\", \"uses\", \"scientific\", \"methods\", \"processes\", \"algorithms\", \"and\", \"systems\", \"to\", \"extract\", \"knowledge\", \"and\", \"insights\", \"from\", \"data\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c514de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dictionary from the articles: dictionary\n",
    "dictionary = Dictionary(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "277a9dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the id for \"computer\": computer_id\n",
    "computer_id = dictionary.token2id.get(\"computer\")\n",
    "computer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47496cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer\n"
     ]
    }
   ],
   "source": [
    "# Use computer_id with the dictionary to print the word\n",
    "print(dictionary.get(computer_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f47e47a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1)],\n",
       " [(3, 1),\n",
       "  (4, 1),\n",
       "  (8, 1),\n",
       "  (13, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1)],\n",
       " [(7, 1),\n",
       "  (27, 1),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 2),\n",
       "  (37, 2),\n",
       "  (38, 1)],\n",
       " [(0, 2),\n",
       "  (5, 1),\n",
       "  (7, 1),\n",
       "  (17, 1),\n",
       "  (19, 2),\n",
       "  (21, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (46, 1),\n",
       "  (47, 1)]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a MmCorpus: corpus\n",
    "corpus = [dictionary.doc2bow(article) for article in articles]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20972da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (5, 1), (7, 1), (17, 1), (19, 2), (21, 1), (27, 1), (28, 1), (39, 1), (40, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 word ids with their frequency counts from the fifth document\n",
    "print(corpus[4][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbab6b5",
   "metadata": {},
   "source": [
    "#### Gensim bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4fedf2",
   "metadata": {},
   "source": [
    "![q6.png](q6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb3a98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92070300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fifth document: doc\n",
    "doc = corpus[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1682d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the doc for frequency: bow_doc\n",
    "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcff2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and 2\n",
      "data 2\n",
      "science 1\n",
      "systems 1\n",
      "algorithms 1\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 words of the document alongside the count\n",
    "for word_id, word_count in bow_doc[:5]:\n",
    "    print(dictionary.get(word_id), word_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "028c0795",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {0: 3,\n",
       "             1: 1,\n",
       "             2: 2,\n",
       "             3: 3,\n",
       "             4: 3,\n",
       "             5: 3,\n",
       "             6: 1,\n",
       "             7: 3,\n",
       "             8: 2,\n",
       "             9: 1,\n",
       "             10: 1,\n",
       "             11: 1,\n",
       "             12: 1,\n",
       "             13: 2,\n",
       "             14: 1,\n",
       "             15: 1,\n",
       "             16: 1,\n",
       "             17: 2,\n",
       "             18: 1,\n",
       "             19: 3,\n",
       "             20: 1,\n",
       "             21: 2,\n",
       "             22: 1,\n",
       "             23: 1,\n",
       "             24: 1,\n",
       "             25: 1,\n",
       "             26: 1,\n",
       "             27: 3,\n",
       "             28: 2,\n",
       "             29: 1,\n",
       "             30: 1,\n",
       "             31: 1,\n",
       "             32: 1,\n",
       "             33: 1,\n",
       "             34: 1,\n",
       "             35: 1,\n",
       "             36: 2,\n",
       "             37: 2,\n",
       "             38: 1,\n",
       "             39: 1,\n",
       "             40: 1,\n",
       "             41: 1,\n",
       "             42: 1,\n",
       "             43: 1,\n",
       "             44: 1,\n",
       "             45: 1,\n",
       "             46: 1,\n",
       "             47: 1})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the defaultdict: total_word_count\n",
    "total_word_count = defaultdict(int)\n",
    "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "    total_word_count[word_id] += word_count\n",
    "total_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c31b96",
   "metadata": {},
   "source": [
    "![q7.png](q7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0462b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5c36065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the fifth document: doc\n",
    "doc = corpus[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "198ef776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the doc for frequency: bow_doc\n",
    "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "750f0167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and 2\n",
      "data 2\n",
      "science 1\n",
      "systems 1\n",
      "algorithms 1\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 words of the document alongside the count\n",
    "for word_id, word_count in bow_doc[:5]:\n",
    "    print(dictionary.get(word_id), word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5716dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the defaultdict: total_word_count\n",
    "total_word_count = defaultdict(int)\n",
    "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "    total_word_count[word_id] += word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f0eced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sorted list from the defaultdict: sorted_word_count\n",
    "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e477c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and 3\n",
      "computers 3\n",
      "of 3\n",
      "science 3\n",
      "systems 3\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 words across all documents alongside the count\n",
    "for word_id, word_count in sorted_word_count[:5]:\n",
    "    print(dictionary.get(word_id), word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906d0db",
   "metadata": {},
   "source": [
    "# Tf-idf with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83109f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
