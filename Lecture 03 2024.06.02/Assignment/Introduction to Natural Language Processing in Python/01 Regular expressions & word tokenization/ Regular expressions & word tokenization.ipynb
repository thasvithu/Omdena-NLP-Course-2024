{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f28b3b",
   "metadata": {},
   "source": [
    "# Regular Expressions\n",
    "- Regular expressions (regex) are sequences of characters that form search patterns used for matching and manipulating strings.\n",
    "- They are commonly used in text processing tasks to find, extract, replace, or split substrings within text based on specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbacc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67605d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"Let's write RegEx!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898fca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', 's', 'write', 'RegEx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all words from a string\n",
    "re.findall(r\"\\w+\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9ca7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L', 'e', 't', 's', 'w', 'r', 'i', 't', 'e', 'R', 'e', 'g', 'E', 'x']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all single word characters from a string\n",
    "re.findall(r\"\\w\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b9f8641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all sequences of whitespace characters from a string\n",
    "re.findall(r\"\\s+\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b67c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 't', 's', 'w', 'r', 'i', 't', 'e', 'e', 'g', 'x']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all individual lowercase letters from a string\n",
    "re.findall(r\"[a-z]\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c4969",
   "metadata": {},
   "source": [
    "#### Practicing regular expressions: re.split() and re.findall()\n",
    "- The re.split() function in Python is used to split a string by the occurrences of a pattern.\n",
    "- The re.findall() function in Python is used to find all occurrences of a pattern in a given string. It returns a list of all non-overlapping matches of the pattern in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d40f5c",
   "metadata": {},
   "source": [
    "![q2](question2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1dd03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's write RegEx\", '']\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "sentence_endings = r\"[.?!]\"\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(sentence_endings, my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3979f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Let', 'RegEx']\n"
     ]
    }
   ],
   "source": [
    "# Find all capitalized words in my_string and print the result\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eded4f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.findall(spaces, my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aec1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find all digits in my_string and print the result\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa9530",
   "metadata": {},
   "source": [
    "# Tokenization \n",
    "-  Breaking down a sentence into smaller pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3147a",
   "metadata": {},
   "source": [
    "![\"Question2\"](Question3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2eca9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd6f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_one = \"Hello there! This is a test string. How are you today? I hope you are doing well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30408d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there!',\n",
       " 'This is a test string.',\n",
       " 'How are you today?',\n",
       " 'I hope you are doing well.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e29cba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(scene_one[3])\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cffd35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '.',\n",
       " '?',\n",
       " 'Hello',\n",
       " 'How',\n",
       " 'I',\n",
       " 'This',\n",
       " 'a',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'hope',\n",
       " 'is',\n",
       " 'string',\n",
       " 'test',\n",
       " 'there',\n",
       " 'today',\n",
       " 'well',\n",
       " 'you'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(scene_one))\n",
    "unique_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366698c",
   "metadata": {},
   "source": [
    "![Question4.png](Question4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61b1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the first occurrence of \"coconuts\" in scene_one: match\n",
    "match = re.search(\"coconuts\", scene_one)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dff0b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(36, 39), match='How'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = re.search(\"How\", scene_one)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "931d85e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_one[36:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d700bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 39\n"
     ]
    }
   ],
   "source": [
    "# Print the start and end indexes of match\n",
    "print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819db766",
   "metadata": {},
   "source": [
    "![Question4](Question5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d3cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"Here is some text with [something] in brackets and [another thing] in brackets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7260737c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[something] in brackets and [another thing]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a regular expression to search for anything in square brackets: pattern1\n",
    "pattern1 = r\"\\[.*\\]\"\n",
    "temp = re.findall(pattern1, my_string)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea1e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(23, 66), match='[something] in brackets and [another thing]'>\n"
     ]
    }
   ],
   "source": [
    "# Use re.search to find the first text in square brackets\n",
    "print(re.search(pattern1, my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1037c",
   "metadata": {},
   "source": [
    "![Question6.png](Question6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07622428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Find the script notation at the beginning of the fourth sentence and print it\n",
    "pattern2 = r\"[\\w\\s]+:\"\n",
    "print(re.match(pattern2, my_string[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd6ec2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(re.match(pattern2, scene_one[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332a9bf",
   "metadata": {},
   "source": [
    "# Advanced tokenization with regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ba0e0",
   "metadata": {},
   "source": [
    "![Question7.png](Question7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3589c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d7b9624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'O',\n",
       " 'L',\n",
       " 'D',\n",
       " 'I',\n",
       " 'E',\n",
       " 'R',\n",
       " '1',\n",
       " 'F',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 'd',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'm',\n",
       " 'I',\n",
       " 'n',\n",
       " 'M',\n",
       " 'e',\n",
       " 'r',\n",
       " 'c',\n",
       " 'e',\n",
       " 'a',\n",
       " 'T',\n",
       " 'h',\n",
       " 'e',\n",
       " 'c',\n",
       " 'o',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'u',\n",
       " 't',\n",
       " 's',\n",
       " 't',\n",
       " 'r',\n",
       " 'o',\n",
       " 'p',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'l']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(\\w)\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e97b967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOLDIER',\n",
       " '1',\n",
       " 'Found',\n",
       " 'them',\n",
       " 'In',\n",
       " 'Mercea',\n",
       " 'The',\n",
       " 'coconut',\n",
       " 's',\n",
       " 'tropical']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(\\w+)\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cf701d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOLDIER',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " 'Found',\n",
       " '',\n",
       " 'them',\n",
       " '',\n",
       " '',\n",
       " 'In',\n",
       " '',\n",
       " 'Mercea',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " '',\n",
       " 'coconut',\n",
       " '',\n",
       " 's',\n",
       " '',\n",
       " 'tropical',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(\\w+|)\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bf5ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOLDIER',\n",
       " '1',\n",
       " 'Found',\n",
       " 'them',\n",
       " '?',\n",
       " 'In',\n",
       " 'Mercea',\n",
       " '?',\n",
       " 'The',\n",
       " 'coconut',\n",
       " 's',\n",
       " 'tropical']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(\\w+|\\?)\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c4127",
   "metadata": {},
   "source": [
    "### Common Regular Expressions Rules and Usage in NLP\n",
    "\n",
    "1. **Matching Characters**:\n",
    "   - `.`: Matches any character except a newline.\n",
    "     ```python\n",
    "     re.findall(r'.', 'Hello')  # Output: ['H', 'e', 'l', 'l', 'o']\n",
    "     ```\n",
    "\n",
    "2. **Character Classes**:\n",
    "   - `\\d`: Matches any digit (0-9).\n",
    "     ```python\n",
    "     re.findall(r'\\d', 'There are 2 apples and 5 bananas.')  # Output: ['2', '5']\n",
    "     ```\n",
    "   - `\\w`: Matches any word character (alphanumeric + underscore).\n",
    "     ```python\n",
    "     re.findall(r'\\w', 'Hello_World!')  # Output: ['H', 'e', 'l', 'l', 'o', '_', 'W', 'o', 'r', 'l', 'd']\n",
    "     ```\n",
    "   - `\\s`: Matches any whitespace character (spaces, tabs, line breaks).\n",
    "     ```python\n",
    "     re.findall(r'\\s', 'Hello World\\n')  # Output: [' ', '\\n']\n",
    "     ```\n",
    "\n",
    "3. **Quantifiers**:\n",
    "   - `*`: Matches 0 or more repetitions.\n",
    "     ```python\n",
    "     re.findall(r'\\d*', '123abc')  # Output: ['123', '', '', '', '', '']\n",
    "     ```\n",
    "   - `+`: Matches 1 or more repetitions.\n",
    "     ```python\n",
    "     re.findall(r'\\d+', '123abc')  # Output: ['123']\n",
    "     ```\n",
    "   - `?`: Matches 0 or 1 repetition.\n",
    "     ```python\n",
    "     re.findall(r'\\d?', '123abc')  # Output: ['1', '2', '3', '', '', '']\n",
    "     ```\n",
    "\n",
    "4. **Anchors**:\n",
    "   - `^`: Matches the start of the string.\n",
    "     ```python\n",
    "     re.findall(r'^Hello', 'Hello World')  # Output: ['Hello']\n",
    "     ```\n",
    "   - `$`: Matches the end of the string.\n",
    "     ```python\n",
    "     re.findall(r'World$', 'Hello World')  # Output: ['World']\n",
    "     ```\n",
    "\n",
    "5. **Groups and Alternation**:\n",
    "   - `(...)`: Groups a pattern.\n",
    "     ```python\n",
    "     re.findall(r'(ab)+', 'ababab')  # Output: ['ab']\n",
    "     ```\n",
    "   - `|`: Acts like a boolean OR.\n",
    "     ```python\n",
    "     re.findall(r'cat|dog', 'cat and dog')  # Output: ['cat', 'dog']\n",
    "     ```\n",
    "\n",
    "6. **Escape Characters**:\n",
    "   - `\\`: Escapes special characters.\n",
    "     ```python\n",
    "     re.findall(r'\\.', '3.14')  # Output: ['.']\n",
    "     ```\n",
    "\n",
    "### Examples in NLP\n",
    "\n",
    "1. **Tokenization**:\n",
    "   - Split a text into words:\n",
    "     ```python\n",
    "     import re\n",
    "     text = \"Hello, world! This is NLP.\"\n",
    "     tokens = re.findall(r'\\w+', text)\n",
    "     print(tokens)  # Output: ['Hello', 'world', 'This', 'is', 'NLP']\n",
    "     ```\n",
    "\n",
    "2. **Removing Punctuation**:\n",
    "   - Remove punctuation from a text:\n",
    "     ```python\n",
    "     import re\n",
    "     text = \"Hello, world! This is NLP.\"\n",
    "     clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "     print(clean_text)  # Output: 'Hello world This is NLP'\n",
    "     ```\n",
    "\n",
    "3. **Extracting Email Addresses**:\n",
    "   - Find all email addresses in a text:\n",
    "     ```python\n",
    "     import re\n",
    "     text = \"Contact us at support@example.com or sales@example.com.\"\n",
    "     emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', text)\n",
    "     print(emails)  # Output: ['support@example.com', 'sales@example.com']\n",
    "     ```\n",
    "\n",
    "4. **Finding Dates**:\n",
    "   - Extract dates in the format `DD/MM/YYYY`:\n",
    "     ```python\n",
    "     import re\n",
    "     text = \"Today's date is 31/05/2024.\"\n",
    "     dates = re.findall(r'\\b\\d{2}/\\d{2}/\\d{4}\\b', text)\n",
    "     print(dates)  # Output: ['31/05/2024']\n",
    "     ```\n",
    "\n",
    "### Practice Example\n",
    "\n",
    "Let's create a pattern to extract hashtags from a tweet:\n",
    "\n",
    "```python\n",
    "    import re\n",
    "\n",
    "    tweet = \"Loving the sunny weather! #sunnyday #beautiful\"\n",
    "    hashtags = re.findall(r'#\\w+', tweet)\n",
    "    print(hashtags)  # Output: ['#sunnyday', '#beautiful']\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- `#\\w+` matches a hashtag, where `#` is the literal character and `\\w+` matches one or more word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce6658a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SOLDIER', '1', 'Found', 'them', '?', 'In', 'Mercea', '?', 'The', 'coconut', 's', 'tropical', '!']\n",
      "['SOLDIER', '#1', 'Found', 'them', '?', 'In', 'Mercea', '?', 'The', 'coconut', 's', 'tropical', '!']\n",
      "[]\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"(\\w+|\\?|!)\", my_string))\n",
    "\n",
    "print(re.findall(r\"(\\w+|#\\d|\\?|!)\", my_string))\n",
    "\n",
    "print(re.findall(r\"(#\\d\\w+\\?!)\", my_string))\n",
    "\n",
    "print(re.findall(r\"\\s+\", my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1d766",
   "metadata": {},
   "source": [
    "# Regex with NLTK tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17c1c4",
   "metadata": {},
   "source": [
    "![Question8.png](Question8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0dcbe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary module\n",
    "from nltk.tokenize import regexp_tokenize, TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a68007",
   "metadata": {},
   "source": [
    "![Question9.png](Question9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd5eb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Loving the sunny weather! #sunnyday #beautiful\",\n",
    "    \"Just finished a great workout. #fitness #health\",\n",
    "    \"Can't wait for the weekend! #TGIF #relaxation\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f948a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#sunnyday', '#beautiful']\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Define a regex pattern to find hashtags: pattern1\n",
    "pattern1 = r\"#\\w+\"\n",
    "\n",
    "# Use the pattern on the first tweet in the tweets list\n",
    "hashtags = regexp_tokenize(tweets[0], pattern1)\n",
    "\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31305acf",
   "metadata": {},
   "source": [
    "![Question10.png](Question10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3d211ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#TGIF', '#relaxation']\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Write a pattern that matches both mentions (@) and hashtags\n",
    "pattern2 = r\"[@#]\\w+\"\n",
    "\n",
    "# Use the pattern on the last tweet in the tweets list\n",
    "mentions_hashtags = regexp_tokenize(tweets[-1], pattern2)\n",
    "\n",
    "print(mentions_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb58dfb",
   "metadata": {},
   "source": [
    "![Question11.png](Question11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3463209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Loving', 'the', 'sunny', 'weather', '!', '#sunnyday', '#beautiful'], ['Just', 'finished', 'a', 'great', 'workout', '.', '#fitness', '#health'], [\"Can't\", 'wait', 'for', 'the', 'weekend', '!', '#TGIF', '#relaxation']]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Use the TweetTokenizer to tokenize all tweets into one list\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d5dff",
   "metadata": {},
   "source": [
    "# Non-ascii tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f94a4",
   "metadata": {},
   "source": [
    "![Question12.png](Question12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7464974",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_text = \"Ich liebe NLP! 🎉 NLP ist faszinierend. Übung macht den Meister. 😄\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec20c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ich', 'liebe', 'NLP', '!', '🎉', 'NLP', 'ist', 'faszinierend', '.', 'Übung', 'macht', 'den', 'Meister', '.', '😄']\n",
      "['Ich', 'NLP', 'NLP', 'Übung', 'Meister']\n",
      "['🎉', '😄']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print all words in german_text\n",
    "all_words = word_tokenize(german_text)\n",
    "print(all_words)\n",
    "\n",
    "# Tokenize and print only capital words\n",
    "capital_words = r\"[A-ZÜ]\\w+\"\n",
    "print(regexp_tokenize(german_text, capital_words))\n",
    "\n",
    "# Tokenize and print only emoji\n",
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(german_text, emoji))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccaa7b2",
   "metadata": {},
   "source": [
    "# Charting practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81846371",
   "metadata": {},
   "source": [
    "![Question13.png](Question13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e95ed568",
   "metadata": {},
   "outputs": [],
   "source": [
    "holy_grail = \"\"\"\n",
    "ARTHUR: What is your name?\n",
    "SOLDIER #1: My name is Arthur, King of the Britons.\n",
    "ARTHUR: What is your quest?\n",
    "SOLDIER #1: To seek the Holy Grail.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f68cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
